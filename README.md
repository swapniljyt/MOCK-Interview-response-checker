# OpenAI-SubjectiveAnswerSheet-Evaluation

Welcome to the OpenAI-SubjectiveAnswerSheet-Evaluation project! This repository is dedicated to evaluating subjective answer sheets using advanced AI models from OpenAI. Our goal is to streamline and automate the evaluation process, ensuring accuracy and efficiency.

## Introduction

Traditional methods of evaluating subjective answers are time-consuming and prone to human errors. This project leverages the power of OpenAI's language models to provide an automated solution for evaluating subjective answer sheets. By utilizing AI, we aim to enhance the accuracy, speed, and consistency of the evaluation process.

## Features

- **Automated Evaluation**: Automatically evaluates subjective answers using AI models.
- **High Accuracy**: Utilizes advanced AI models to ensure accurate grading.
- **Scalability**: Capable of evaluating large volumes of answer sheets efficiently.
- **Customizable Rubrics**: Supports custom grading rubrics for diverse evaluation criteria.

## Installation

To get started with the OpenAI-SubjectiveAnswerSheet-Evaluation project, follow these steps:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/swapniljyt/OpenAI-SubjectiveAnswerSheet-Evaluation.git
   cd OpenAI-SubjectiveAnswerSheet-Evaluation
